{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Creating a simple neural network\n",
    "# Creates one input and one output layer\n",
    "# Following https://stackabuse.com/creating-a-neural-network-from-scratch-in-python/?fbclid=IwAR0rIDS4fz-vXwqcKB15vqWvifosCUaebGrVJM2uTSXWo2IuUAj5uGGx8KI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change working directory\n",
    "%cd \"C:\\\\Users\\\\espop\\\\OneDrive\\\\Documents\\\\Industry_Job\\\\Python practice\\\\Neural networks\\\\\"\n",
    "# Get current working directory\n",
    "#%pwd\n",
    "# Save notebook file\n",
    "%notebook NeuralNetwork.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed\n",
    "np.random.seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Input data\n",
    "\n",
    "# create feature set of five people (smoking, obesity, exercise; 1 =  true, 0 = false)\n",
    "feature_set = np.array([[0,1,0],[0,0,1],[1,0,0],[1,1,0],[1,1,1]])\n",
    "# Add labels (diabetic; 1 =  true, 0 = false)\n",
    "labels = np.array([[1,0,0,1,1]])\n",
    "# Reshape labels into five rows and one columns\n",
    "labels = labels.reshape(5,1) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define hyperparameters\n",
    "\n",
    "# Set weights\n",
    "weights = np.random.rand(3,1)  \n",
    "# Set bias\n",
    "bias = np.random.rand(1)  \n",
    "# Set learning rate\n",
    "lr = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Define the activation function\n",
    "\n",
    "# Sigmoid function\n",
    "def sigmoid(x):  \n",
    "    return 1 / (1 + np.exp(-x) )\n",
    "# randomly generate 100 linearly-spaced points between -10 and 10\n",
    "input = np.linspace(-10, 10, 100)\n",
    "# Plot the sigmoid function\n",
    "plt.plot(input, sigmoid(input), c = \"r\")\n",
    "# Derivative of sigmoid function\n",
    "def sigmoid_der(x):  \n",
    "    return sigmoid(x)*(1-sigmoid(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train network\n",
    "\n",
    "# Repeat 20.000 times\n",
    "for epoch in range(20000):  \n",
    "    \n",
    "    # Feedforward step 1: multiply the inputs and weights\n",
    "    # Calculate the dot product of the input and the weight vector and add bias to it\n",
    "    XW = np.dot(feature_set, weights) + bias\n",
    "\n",
    "    # Feedforward step 2: Pass through an activation function\n",
    "    # Pass the dot product through the sigmoid activation function to predict output\n",
    "    z = sigmoid(XW)\n",
    "\n",
    "    # Backpropagation step 1: Calculate the cost\n",
    "    # Find the error (difference between predicted labels and observed labels)\n",
    "    error = z - labels\n",
    "    # Print the summed error\n",
    "    print(error.sum())\n",
    "\n",
    "    # Backpropagation step 2: Minimize the cost\n",
    "    # 2(predicted - observed) where the 2 is constant and can be ignored\n",
    "    dcost_dpred = error\n",
    "    # Derivative sigmoid of the dot product\n",
    "    dpred_dz = sigmoid_der(XW)\n",
    "    \n",
    "    # Predicted output multiplied with its cost\n",
    "    z_delta = dcost_dpred * dpred_dz\n",
    "    # transpose of the input feature matrix. \n",
    "    inputs = feature_set.T\n",
    "    # Calculate dor-product of the transposed input and the z_delta\n",
    "    # And multiply the learning rate variable lr with the derivative to increase the speed of convergence\n",
    "    weights -= lr * np.dot(inputs, z_delta)\n",
    "    \n",
    "    # Adjust the bias by multiplying the learning rate with the z_delta\n",
    "    for num in z_delta:\n",
    "        bias -= lr * num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict new observation\n",
    "# New observation smokes, is not obese, and doesn't exercise\n",
    "single_point = np.array([1,0,0])\n",
    "# Predict whether new observation is diabetic or not\n",
    "result = sigmoid(np.dot(single_point, weights) + bias)\n",
    "# Print predicted label\n",
    "print('The chance of diabetes is %.2f percent.' % (result*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict another new observation\n",
    "# New observation doesn't smoke, is obese, and doesn't exercise\n",
    "single_point = np.array([0,1,0])\n",
    "# Predict whether new observation is diabetic or not\n",
    "result = sigmoid(np.dot(single_point, weights) + bias)\n",
    "# Print predicted label\n",
    "print('The chance of diabetes is %.2f percent.' % (result*100))"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 2
}
